2. 数字图像基础
	- 空间分辨率
		- PPI：单位英寸（长度）像素数
		- DPI：每英寸点数
	- 像素位深度b，动态变化范围$L=2^b$
	- 灰度图像表示：矩阵、二维数组等
	- 基本操作
		- 点运算（线性/非线性）
		- 代数运算：图像的加减乘（哈达玛积，对应位置乘法）除
3. 深度学习基础
	- 深度卷积神经网络CNN：输入层、卷积层、激活层、池化层、全连接层（参数量在维数大时过大）
	- 卷积：翻转，乘，求和
	- 直接卷积图像变小->边缘填充常数（0）或者复制边界
	- 权值共享：共享卷积核，减少参数量
	- 多喝卷积，多通道输出，兼顾特征表达能力和参数量
	- 池化
		- 数据压缩，不改变通道数，特征降维，减少计算，防止过拟合
		- 下采样$g(x)=f(tx+k)$，最大池化（邻域最大值），平均池化
	- 数据扩充：图像放缩、旋转、亮度变换、色度变换、添加噪声等
	- 优化算法：随机梯度下降法、动量法、Adam
4. 图像变换
	- 空域变换
		- 几何变换：平移，旋转，镜像，缩放，欧式变换（旋转+缩放），相似变换（欧式+缩放），仿射，射影
		- 灰度变换$I'=T(I)$
			- 线性变换$I'=a\cdot I+b$（$a>1$对比度增加，$b>0$亮度提高）
			- 对数变换$I'=b+clog(1+I)$
			- 伽马变换$I'=cI^\gamma$
	- 频域变换
		- 图像的离散二维傅里叶变换DFT：$$F(u,v)=\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)e^{-j2\pi (ux/M+vy/N)}$$逆变换IDFT：$$f(x,y)=\frac{1}{MN}\sum_{u=0}^{M-1}\sum_{v=0}^{N-1}F(u,v)e^{j2\pi (ux/M+vy/N)}$$
		- 图像增强：增强图像对比度、清晰度（提升低频）
		- 噪声去除：去高频
		- 图像压缩：去除图像小于一定阈值分量
		- 特征提取：分析特定频率
		- 问题：是全局变换，缺少定位功能
5. 图像处理与数字滤波器
	- 卷积性质：
		- 交换、分配、结合
		- 微分$(f*h)'=f'*h=f*h'$
		- 卷积定理
	- 高斯噪声，椒盐噪声（随机0或255点），泊松噪声
	- 高斯滤波：对邻域中点按高斯分布加权平均（$3\sigma$原则，$S=round\_up(3\sigma)*2+1$）
	- 双边滤波：权重同时考虑像素值
	- 低通滤波（模糊平滑），高通滤波（边缘锐化），带通滤波
	- 采集造成图像退化：$g(x,y)=h(x,y)*f(x,y)+\eta (x,y)$
	- 维纳滤波：$\hat{F}(u,v)=[\frac{1}{H(u,v)}\frac{|H(u,v)|^2}{|H(u,v)|^2+S_\eta(u,v)/S_f(u,v)}]G(u,v)$
		- $S_\eta(u,v)=|N(u,v)|^2$：噪声功率谱
		- $S_f(u,v)=|F(u,v)|^2$：输入图像功率谱，由参考图像近似计算
		- $S_\eta(u,v)/S_f(u,v)$：信号噪声比，值越小噪声越强
6. 形态学与基于深度学习的图像去噪
	- 形态学
		- 结构元素
		- 膨胀$\oplus$
		- 腐蚀$\ominus$
		- 开运算$\circ$：先腐蚀再膨胀$A\cdot B = (A\ominus B) \oplus B$
			- $A\circ B\subseteq A, C\subseteq A\Rightarrow (C\circ B)\subseteq (A\circ B), (A\circ B)\circ B=A\circ B$
			- 轮廓变平滑，断开狭窄的间断和消除细的突出物
			- 与腐蚀类似，对图像破坏较小
		- 闭运算$\cdot$：先膨胀再腐蚀$A\cdot B = (A\oplus B) \ominus B$
			- $A\subseteq A\cdot B, C\subseteq A\Rightarrow (C\cdot B)\subseteq (A\cdot B), (A\cdot B)\cdot B=A\cdot B$
			- 轮廓变平滑，填充狭窄间断和细长鸿沟
			- 与膨胀类似，对图像破坏较小
		- 边界提取：$\beta(A)=A-(A\ominus B)$
		- 区域填充：$X_k=(X_{k-1}\oplus B)\cap A^C$，十字中心结构元
		- 提取连通分量：$X_k=(X_{k-1}\oplus B)\cap A$，九宫格中心结构元
	- 基于深度学习
		- DnCNN：卷积神经网络，残差学习，降噪图像为原图与预测的噪声之差
		- DVDNet：基于CNN，视频降噪，增加时间域降噪
7. 图像增强
	- 突出感兴趣的特征，抑制不需要的特征
	- 基于空域的图像增强
		- 灰度直方图
			- 直方图均衡化$$S_k=T(r_k)=\sum_{i=0}^k\frac{n_i}{n}$$
			- 局部直方图均衡化：基于目标邻域设计映射，但仅作用于目标区域
			- 直方图匹配（规定化）：原始图像均衡化，目标图像求变换函数，用其逆作用于均衡化的图像
		- 空间域滤波器
			- 空间域平滑
				- 均值滤波器
				- 超限像素平滑法：
					- 变化绝对值大于阈值时保留变化
					- 有效抑制椒盐噪声，保护微小纹理细节
				- K近邻平滑法：
					- 对邻域内灰度最接近的K个像素平均值作为结果
					- 保留细节好，平滑能力差
					- 一般$3\times 3$取$K=6$
				- 最大均匀性平滑
				- 中值滤波器：
					- 中位数
					- 抑制椒盐噪声，保护边缘
					- 不适合点线
			- 空间域锐化：
				- 梯度锐化法$\begin{bmatrix}-1&1\end{bmatrix}$，$\begin{bmatrix}-1\\1\end{bmatrix}$
				- Roberts算子$\begin{bmatrix}-1&0\\0&1\end{bmatrix}$，$\begin{bmatrix}0&-1\\1&0\end{bmatrix}$
				- Prewitt算子$\begin{bmatrix}-1&-1&-1\\0&0&0\\1&1&1\end{bmatrix}$，$\begin{bmatrix}-1&0&1\\-1&0&1\\-1&0&1\end{bmatrix}$，$\begin{bmatrix}0&1&1\\-1&0&1\\-1&-1&0\end{bmatrix}$，$\begin{bmatrix}-1&-1&0\\-1&0&1\\0&1&1\end{bmatrix}$
				- Sobel算子$\begin{bmatrix}-1&-2&-1\\0&0&0\\1&2&1\end{bmatrix}$，$\begin{bmatrix}-1&0&1\\-2&0&2\\-1&0&1\end{bmatrix}$，$\begin{bmatrix}0&1&2\\-1&0&1\\-2&-1&0\end{bmatrix}$，$\begin{bmatrix}-2&-1&0\\-1&0&1\\0&1&2\end{bmatrix}$
		- 基于频域的图像增强
			- 傅里叶变换->滤波->逆变换
			- 理想低通
			- 巴特沃斯低通$H(u,v)=\frac{1}{1+(\frac{\sqrt{u^2+v^2}}{D_0})^{2n}}$
			- 理想高通
			- 巴特沃斯高通$H(u,v)=\frac{1}{1+(\frac{D_0}{\sqrt{u^2+v^2}})^{2n}}$
		- 基于深度学习的图像增强
			- 超分辨率：插值上采样
			- 多尺度，生成低分辨率再逐步扩大分辨率
8. 图像复原
	- 图像退化
		- 线性空间不变近似：$g(x,y)=f(x,y)*h(x,y)+n(x,y)$
			- 线性：均匀性，相加性
			- 时不变：参数不随时间变化
			- 空间不变：参数不随位置变化$H[f(x-a,y-b)]=g(x-a,y-b)$
		- 噪声：高斯，瑞利，伽马，指数分布，均匀分布，脉冲
		- $[g]=[H][f]+[n]$，$[g]$$[f]$为MN维列向量，各列为$M\times N$维矩阵$[f_e(x,y)]$$[g_e(x,y)]$的各行
	- 无约束图像复原
		- $argmin J(\hat{f})=argmin||g-H\hat{f}||$
		- $\hat{f}=H^{-1}g$
		- 逆滤波$f(x,y)=\mathcal{F}^{-1}[\frac{G(u,v)-N(u,v)}{H(u,v)}]$，$H(u,v)$逆滤波器
		- 动态模糊$H(u,v)=\frac{T}{\pi(ua+vb)}sin[\pi(ua+vb)]e^{j\pi(ua+vb)}$
	- 有约束图像复原
		- 代数有约束复原：
			- 令Q线性算子，$argmin||Q\hat{f}||^2 s.t.||n||^2=||g-H\hat{f}||^2$，拉格朗日乘数法：$\hat{f}=(\frac{1}{\lambda}Q^TQ+H^TH)^{-1}H^Tg$
			- $argmin||g-H\hat{f}||^2 s.t. ||g||^2=||\hat{f}||^2$等
	- 基于深度学习的图像复原
		- 基于CNN：MPRNet
		- 基于GAN：DGP
		- 基于Transformer：IPT
		- 基于MLP：MAXIM
9. 图像压缩
	- 信息量，信息熵
		- 熵$H(x)=-\sum_{i=1}^\infty p(a_i)log_2p(a_i)$
		- 互信息$I(X,Y)=H(X)+H(Y)-H(X,Y)$
		- 条件熵$H(Y|X)=H(X,Y)-H(X)$
		- 相对熵（KL散度）$D_{KL}(P||Q)=E_{x\sim P}[log\frac{P(x)}{Q(x)}]$
		- 交叉熵$H_{ce}(P,Q)=-E_{x\sim P}[logQ(x)]$
	- 编码
		- 等长码
		- 变长码
		- 压缩率$CR=n_1/n_2>1$
	- 无损压缩
		- 霍夫曼编码
			- 变长，平均码长接近信息熵
			- 迭代合并最小频率编码子树，形成哈夫曼树和查询表
			- 最优变长编码，快码（固定查询表），即时码（每个码字不考虑后续符号即可解出）
			- 给定数据对应霍夫曼编码不一定唯一
		- 算术编码
			- 对更高频次字符赋予更大小数区间
			- 逐字符按比例细分对应区间，在最终区间内选择最短二进制数（小数部分）
			- 解码：根据比例重新划分区间
	- 有损压缩
		- 变换编码：空域图像信号变换到正交空间中，变换系数量化进行压缩，反变换解压
		- 要求：二维正交变换，可逆，不太过复杂，集中信息在低频成分，边缘、线状信息在高频分量
		- 离散傅里叶变换DFT、离散余弦变换DCT、沃尔什-哈达玛变换WHT
	- 基于深度学习的图像压缩
		- CNN，RNN，GAN
10. 图像物体表达
	- 传统识别：监督学习
		- VGGNet：卷积/下采样->全连接
		- DeepID：利用DNN提取人脸特征
		- VS2VI：具有视角不变性的DNN
	- 小样本
		- 少量有标注
		- 基于度量学习、无学习、数据增强的方法
	- 零样本
		- 已知有标注的意见类别标注和语义特征，识别未见类别数据
			- 传统零样本学习ZSL：正确分类不可见类别样本
			- 广义零样本学习GZSL：正确分类不可见类别样本和可见类测试样本
		- 方法分类
			- 归纳式/直推式
			- 基于表征学习（视觉到语义、语义到视觉、隐空间方法）/基于生成模型（GAN、变分自编码器）
		- 问题：
			- 域漂移：不适用于未知领域
			- 域偏置：倾向于已知领域
		- 生成对抗网络GAN：生成网络G（通过噪声生成假图像）和判别网络N（判断真假）
	- 开集识别：既要正确分类已知样本，也有识别未知类别样本
		- 难点：特征混淆（已知类别之间&已知类别与未知类别之间）
		- 方法
			- 判别式方法：k类->(k+1)类分类
			- 生成式方法：建模已知类，判断是否符合其分布
	- 神经场景表达
		- 通过生成式查询和绘制网络来学习场景表达
		- 神经辐射场NeRF：对目标场景进行隐式建模，由相机位姿直接推测该视角下场景图像
11. 目标检测
	- 视频目标检测（运动检测）：提取运动前景&预测背景相减得到前景
		- 背景差法：通过计算图像与背景差别，设定阈值得到运动前景区域
			- 单高斯模型：单像素用高斯模型描述（背景可能变换），等价于直接求均值
			- 混合高斯模型（K取3~7）：K个高斯模型加权
				- 训练：对每幅图像该点像素值作为均值，给定较大方差和较小权值进行训练，得到K个模型后较优模型替代较差模型，定义优先级$p=\omega / \sigma$，选取前B个分布使得优先级之和大于阈值M
				- 前景检测：每个像素点与该点对应每个模型进行比对，如果其一满足$|z-\mu|<a\sigma$，则属于背景；都不满足，则属于前景
		- 光流：运动场，图像亮度模式的表观运动，二维矢量场
			- 光流一致性假设：$I(x+u\Delta t, y+v\Delta t, t+\Delta t)=I(x,y,t)$（只考虑相邻两帧）
			- 光流约束方程：$I_xu+I_yv+I_t=0$
			- 其中$I_x=\frac{\partial I}{\partial x},I_y=\frac{\partial I}{\partial y},I_t=\frac{\partial I}{\partial t},u=\frac{\partial x}{\partial t},v=\frac{\partial y}{\partial t}$
			- 欠约束，只用一个点信息不能确定光流
			- 增加其他约束：基于梯度/匹配/能量/相位的方法，神经动力学方法
			- 基于梯度的方法
				- 通常约束：光流场局部平滑
				- Lucas-Kanade方法约束（更强）：每个像素邻域内像素均有相对的速度$$E(u,v)=\sum_{(x,y)\in\Omega}(I_xu+I_yv+I_t)^2$$
					- $A\vec{U}=b,A=\Sigma \nabla I\nabla I^T,\vec{U}=[u,v]^T,b=-\Sigma \nabla II_t$
					- 化为最小二乘问题
					- 直观，不易受运动物体外观影响；计算量大，易产生较大噪声
		- 帧间差分
			- 双帧差分：相邻两帧灰度差与阈值比较
			- 扩展：三帧差分
			- 优点：适合动态变化背景
			- 缺点：较难检测运动较快、较慢和多个运动物体
	- 图像目标检测
		- 传统方法
			- 滑窗法：不同窗口尺寸进行华创操作
			- AdaBoost
				1. Haar-like特征
				2. 选择最优特征，形成弱分类器
					1. 找到弱分类器$h_t$，得到误差$\epsilon_t$
					2. 计算分类器权重$\alpha_t=\frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t})$
					3. 更新样本权重$D_{t+1}=\frac{D_t(i)}{Z_t}\times\begin{cases}e^{-\alpha_t}&h_t(x_i)=y_i\\e^{\alpha_t}&h_t(x_i)\neq y_i\end{cases}$，$Z_t$归一化因子
					4. 输出$H(x)=sign(\sum_{t=1}^T\alpha_th_t(x))$
				3. AdaBost级联检测：全部强分类器均判定为人脸才输出为人脸，否则非人脸
		- 基于DNN的目标检测
			- 两阶段检测器：生成候选框->提取特征、分类、回归
				- RCNN：找到可能含物体区域->reshape与CNN+SVM分类检测、边界框回归（边界框微调再检测）
				- $IoU=(A\cap B)/(A\cup B)$
			- YOLO：直接从图像像素预测包围框以及概率
				- 图像分割成$S\times S$ grid cells
				- 每个grid cell产生B个包围框及其置信度（框中心、框尺寸+置信度共五个值）
				- 每个grid cell产生C个类别的概率
				- 输出：$S\times S\times (B\times 5+C)$张量
12. 图像分割
	- 基本图像分割-（加类别）->语义分割-（区分同类个体）->实例分割
	- 难点：歧义性（尺度相关），依赖于低层、高层视觉，视角、光照、干扰
	- 早期方法
		- 阈值法：特征根据阈值进行分类
			- p-分位数法
			- 众数法
			- 全局阈值法：初始为均值$T_0$，小于部分均值为$T_A$，大于部分均值为
			  $T_B$，$T_{i+1}=T_{Ai}+T_{Bi}$迭代至收敛
			- 局部阈值法：分块进行全局阈值法迭代，最后综合
			- 区域生长法：种子区域以8邻域向外生长，差值小于阈值即归入目标区域
		- 分水岭分割法
			- 图像看作地形图，极小点处喷水，保持水位一致，不同盆地水相遇则筑坝，水位达到地形最高点时终止
			- 有标记版：手工/自动指定泉眼
		- 基于均值移动的图像分割方法
			- 每点基于核函数加权进行均值移动至收敛
			- 合并收敛位置距离小于预设点，确定聚类集合
			- 赋予标签
	- 基于图割的图像分割
		- 归一化割Normalized Cut
			- 邻接矩阵刻画相似度有向赋权图，最优划分对应最小Ncut
			- NP问题，但是可求$(W-D)x=\lambda Dx$次小特征值，对应特征向量对应最优划分，D为W列和形成的对角阵
		- 图割graph cut
			- 最小化能量函数$E(f)=E_{data}(f)+E_{smooth}(f)=\sum_{p\in P}F_p(f_p)+\sum_{\{p,q\}\in N}V_{pq}(f_p,f_q)$，$F_p(f_p)$为每个像素赋予标签代价，$V_{pq}(f_p,f_q)$为相邻像素赋予标签$f_p,f_q$代价
			- 两标记：最小能量$\Leftrightarrow$最小割
			- 多标记：NP hard，近似算法$\alpha-\beta$ swap；$\alpha$ expansion
		- FCN：卷积+上采样+skip
		- SegNet
		- DeepLab
13. 图像局部特征提取与匹配
	- 点-线-区域
	- 边缘检测
		- 边缘产生：物体的边界，表面方向的改变，不同的颜色，光照明暗的变化
		- 微分算子
			- 消除噪声：先高斯平滑，再一阶差分；或者直接用微分后的高斯进行卷积
			- Laplacian算子模板$\begin{bmatrix}0&-1&0\\-1&4&-1\\0&-1&0\end{bmatrix}$，$\begin{bmatrix}-1&-1&-1\\-1&8&-1\\-1&-1&-1\end{bmatrix}$对噪声更敏感，需先平滑
			- Laplacian of Gaussian（LoG）：先高斯平滑，再用Laplacian算子（可用不同尺度）$\nabla^2(G(x,y)*I(x,y))=\nabla^2(G(x,y))*I(x,y)$
			- LoG算子：$\nabla^2G(x,y)=-\frac{x^2+y^2-\sigma^2}{\sigma^4}e^{\frac{x^2+y^2}{2\sigma^2}}$
			- 得到图像大于0置1，否则置0，再形态学膨胀
		- Canny边缘检测器
			- 计算图像梯度
				- 高斯平滑，用$\begin{bmatrix}-1&1\\-1&1\end{bmatrix}$，$\begin{bmatrix}1&1\\-1&-1\end{bmatrix}$得到$D_x$，$D_y$，并求得赋值方向
			- 非极大值抑制NMS
				- 如果一点是梯度方向上极大值则保留，否则丢弃
				- 简化：仅4个方向
				- 双阈值化处理：大阈值点集通过邻域和小阈值点集交集进行扩充至收敛
	- 角点检测
		- Harris角点检测
			- 小窗观察图像，向任何方向移动都会导致灰度变化
			- 窗口函数可用均值或高斯加权
			- 则可分析$\begin{bmatrix}I_x^2&I_xI_y\\I_xI_y&I_y^2\end{bmatrix}$，特征值$\lambda_1$，$\lambda_2$有$\begin{cases}\lambda_1\gg\lambda_2或\lambda_2\gg\lambda_1&为边\\\lambda_1\sim\lambda2\gg0&为角点\\\lambda_1\sim\lambda2\approx0&为平坦区域\end{cases}$
			- 角点响应函数$R=det(M)-k(traceM)^2$，$k=0.04\sim0.06$，则类似$\begin{cases}R\gg0&角点\\R\ll0&边缘\\R\sim0&平坦\end{cases}$
			- 提取R的局部极大值
			- 具有旋转不变性（椭圆旋转特征值不变）、灰度仿射（$I_1=aI+b$）（平移不变，尺度可能变化）变化部分不变性，对几何尺度不具有不变性
		- SIFT特征点检测
			- 不变性：旋转、尺度、视角、光照、局部特征
			1. 多尺度空间点检测
				1. 高斯差分（DoG）$D(x,y,\sigma)=(G(x,y,k\sigma)-G(x,y,sigma))*I(x,y)=L(x,y,k\sigma)-L(x,y,\sigma)$
				2. 即用不同方差高斯核进行卷积得到多通道特征，再通道间进行差分，$k=\sqrt{2},2,2\sqrt{2}...$
				3. 高斯金字塔：卷积后图像降尺寸再进行差分同尺寸叠加成张量
				4. DoG尺度空间极值点检测：若为26邻域局部极值点则保留
			2. 关键点精确定位（离散采样局部极值不一定是真实空间极值）
				1. 对尺度空间DoG函数进行三元二次函数拟合$D(x)=D+\frac{\partial D^T}{\partial x}x+\frac{1}{2}x^T\frac{\partial^2 D}{\partial x^2}x$
				2. 改变关键点初始位置，重复计算精细偏移量$\hat{x}=-\frac{\partial^2 D^{-1}}{\partial x^2}\frac{\partial D}{\partial x}$，$\hat{x} = (\hat{x},\hat{y},\hat{\sigma})$，若任意值大于0.5则重复
				3. 去除对比度低的点$D(\hat{x})=D+\frac{\partial D^T}{\partial x}\hat{x}$，阈值$|D(\hat{x})|<0.03$
				4. 去除边缘点，Hessian矩阵$H=\begin{bmatrix}D_{xx}&D{xy}\\D{xy}&D{yy}\end{bmatrix}$，特征值$\lambda_1=r\lambda_2$，$\frac{Tr^2(H)}{Det(H)}=\frac{(\lambda_1+\lambda_2)^2}{\lambda_1\lambda_2}=\frac{(r+1)^2}{r}>\frac{(10+1)^2}{10}$
			- 不足
				- 边缘点可能有用
				- 先验知识需要较多
				- 超参多
	- 特征点描述与匹配
		- 点、直线、曲线、区域匹配
		- Cross-correlation基本原理：
			- 利用相关函数评价两幅图像特征点邻域的灰度相似性以确定对应点
			- 相关函数：$Score(m_1,m_2)=\frac{\sum_{i=-n}^n\sum_{j=-m}^m[I_1(u_1+i,v_1+j)-\bar{I}(u_1,v_1)]\times[I_2(u_2+i,v_2+j)-\bar{I}(u_2,v_2)]}{(2n+1)(2m+1)\sigma_1(I_1)\sigma_2(I_2)}$
			- 左图每个特征点对应右图一个候选集，反之亦然
			- 特征：给予灰度，窗口大小和形状是超参，没有旋转不变性，光照变化敏感，计算代价大
		- SIFT特征匹配算法
			3. 主方向计算
				1. 邻域分为角度区间
				2. 统计梯度幅值和（最大为主方向）
				3. 抛物线插值精确定位主方向
			4. SIFT描述子构造
				1. 关键点邻域分为$4\times4$个子区域
				2. 梯度方向划分为8个方向
				3. 直方图的值为梯度幅值累加
				4. 得到$4\times4\times8=128$维向量
				- 梯度直方图：适应图像局部性变适应
				- 子区域：划分弥补丢失的位置信息
				- 邻域、子区域进行类似高斯加权，强化中心区域
				- 尺度、旋转不变性，适应复杂几何变形，适应复杂光照（线性光照归一化向量，非线性光照将向量中大于0.2的元素赋值0.2）
			5. SIFT特征匹配匹配准则
				1. 匹配准则$NNDR=\frac{d(m,m_1)}{d(m,m_2)}$
				2. 搜索算法：BBF算法
		- 特征描述子学习网络
			- L2-Net
				- 输入：以特征点的图像面片patch
				- 输出：128维单位向量描述子（单位向量数值稳定性更高）
				- 欧氏距离下的高性能描述子L2Ne
		- 鲁棒匹配的RANSAC框架
			1. 确定求解模型所需要最小数据点n
			2. 随机抽取样本$J$得到模型$M(J)$，将样本中几何距离小于阈值t的数据点构成$M(J)$的一致集$S(M(J))$
			3. 如果一致集数据点数大于阈值T，则利用一致集重新估计模型M并输出结果，否则重新抽取
			4. 若K次都没有输出，选取最大一致集，由其重新估计模型M并输出
14. 视觉几何初步
	- 成像基本原理
		- 针孔相机：屏障阻挡大部分光线，小孔称为光圈（大则模糊，小则光量少，衍射）
		- 凸透镜锐化聚焦，光线聚成一团（弥散圈），聚成一点（聚焦），薄透镜$\frac{1}{d_0}+\frac{1}{d_1}=\frac{1}{f}$
		- 景深：较小光圈可增加物体近似聚焦范围
		- 视角：与焦距和胶片尺寸有关
	- 摄像机模型
		- 相机-世界（刚体变换）：$P_c=R(P_w-C)=RP_w+T$，$M_{ext}=\begin{bmatrix}r{11}&r{12}&r{13}&t_x\\r{21}&r{22}&r{23}&t_y\\r{31}&r{32}&r{33}&t_z\\0&0&0&1\end{bmatrix}$$$\begin{bmatrix}X\\Y\\Z\\1\end{bmatrix}=\begin{bmatrix}r{11}&r{12}&r{13}&t_x\\r{21}&r{22}&r{23}&t_y\\r{31}&r{32}&r{33}&t_z\\0&0&0&1\end{bmatrix}\begin{bmatrix}U\\V\\W\\1\end{bmatrix}$$
		- 透视投影（透视投影）$M_{proj}=\begin{bmatrix}f&0&0&0\\0&f&0&0\\0&0&1&0\end{bmatrix}$，更一般地$$\begin{bmatrix}x'\\y'\\z'\end{bmatrix}=\begin{bmatrix}f/s_x&s&o_x&0\\0&f/s_y&o_y&0\\0&0&1&0\end{bmatrix}\begin{bmatrix}X\\Y\\Z\\1\end{bmatrix}$$
		- 像素-照片（仿射）$M_{aff}=\begin{bmatrix}a{11}&a{12}&a{13}\\a{21}&a{22}&a{23}\\0&0&1\end{bmatrix}$$$\begin{bmatrix}u'\\v'\\w'\end{bmatrix}=\begin{bmatrix}a{11}&a{12}&a{13}\\a{21}&a{22}&a{23}\\0&0&1\end{bmatrix}\begin{bmatrix}x'\\y'\\z'\end{bmatrix}$$
		- $$\begin{bmatrix}u\\v\\1\end{bmatrix}\sim M_{aff}M_{proj}M_{ext}\begin{bmatrix}x'\\y'\\z'\end{bmatrix}$$
		- 内参矩阵$$K=M_{int}=M_{aff}M{proj}=\begin{bmatrix}a{11}&a{12}&a{13}\\a{21}&a{22}&a{23}\\0&0&1\end{bmatrix}\begin{bmatrix}f/s_x&s&o_x&0\\0&f/s_y&o_y&0\\0&0&1&0\end{bmatrix}$$
	- 其他类型相机
		- 仿射相机
		- 反射折射镜头
		- 鱼眼镜头
	- 射影几何基础知识
		- $m=[x,y,z]^T$，$[m]_{\times}=\begin{bmatrix}0&-t&y\\t&0&-x\\-y&x&0\end{bmatrix}$
			- $rank[m]_{\times}=2,m^T[n]_{\times}m=0$
		- 无穷远元素
		- 齐次坐标
			- $x=c_1x_1+c_2x_2$，射影参数$\frac{c_1}{c_2}$
			- 交比$\frac{(\theta_1-\theta_3)(\theta_2-\theta_4)}{(\theta_2-\theta_3)(\theta_1-\theta_4)}$，24种排列组合，6个值
			- 点线结合关系和交比在射影变换下保持不变
			- 二维摄影变换$dof=8$，可逆
			- 三维摄影变换$dof=15$，可逆
	- 消隐点与消隐线
		- 消隐点：无穷远点在图像平面投影
		- 消隐线：无穷远直线在图像平面投影，不同平面定义不同消隐线
	- 单应矩阵：
		- 中心投影：二维射影变换，一一对应
		- 一般平面投影：平面点和像素坐标系一一对应
		- 纯旋转拍摄的像素坐标系之间也是单应
		- H的$dof=8$，一对对应点提供两个约束，4对对应点可以确定H，多于4对可以通过最小二乘优化 
		- 拼接：假设场景大致是平面，否则会重影
	- 双目立体视觉，简单立体系统：
		- 世界坐标系与左相机对齐
		- 视差计算：确定一一对应关系
		- 极线约束：只需搜索一维直线
	- 双视点几何
		- 外极限约束：左图$m$点对应右图外极线$l$，右图$m'$点对应左图外极线$l'$
		- 基线：光心$OO'$连线
		- 外极点：$OO'$与图像平面交点$e$，$e'$
		- 外极平面：任意外点M（三维），平面$OO'M$
		- 外极线：外极平面与图像平面交线$l$，$l'$
		- 本质矩阵：$E=[t]_{\times}R\in R^{3\times3}$，$rank(E)=2$，$dof=9-4=5$，$M'^TEM=0$
		- 基本矩阵：$F=K'^{-T}EK^{-1}=K'^{-T}[t]_{\times}RK^{-1}\in R^{3\times3}$，$rank(F)=2$，$dof=9-2=7$，$m'^TFm=0$，刻画像素之间的约束
		- $l'=Fm$，$l=F^Tm'$
		- 基本矩阵估计：8点法（每对点提供一个约束）线性求解，7点非线性求解，大于等于8对最小二乘线性求解并调整$f=Udiag(s_1,s_2,0)V^T$保证$dof=7$
		- RANSAC可以减少误匹配影响
15. 视觉重建与定位
	- 相机标定：获得相机内外参数
		- 内参数：$K=\begin{bmatrix}f_x&0&p_x\\0&f_y&p_y\\0&0&1\end{bmatrix}$
		- 外参数：不同相机坐标系（同一相机不同时刻下旋转平移关系）
		- 基于三维标志物的标定：精度高，计算简单，只需一幅图像
			- $\lambda\begin{bmatrix}u\\v\\1\end{bmatrix}=\begin{bmatrix}f_u&s&u_0\\0&f_v&v_0\\0&0&1\end{bmatrix}\begin{bmatrix}R|t\end{bmatrix}\begin{bmatrix}X_w\\Y_w\\Z_w\\1\end{bmatrix}=K\begin{bmatrix}R|t\end{bmatrix}\begin{bmatrix}X_w\\Y_w\\Z_w\\1\end{bmatrix}=P\begin{bmatrix}X_w\\Y_w\\Z_w\\1\end{bmatrix}$
			- 直接线性变换法DLT
				- P自由度11，需要大于等于6对点
				- $m_i=PM_i$，$m_i\times PM_i=0$，每对点提供两个约束
				- 退化配置：三维点位于一个平面上或者过相机中心的直线上；三维点和相机位于一个扭三次曲线上
			- 黄金标准算法
				- 线性求解：归一化，DLT
				- 几何误差最小化
				- 去归一化
		- 基于二位标志物的标定：张正友平面标定方法：采用单平面，简单，但仍需点阵坐标与图像点匹配关系
			- $R=\begin{bmatrix}r_1&r_2&r_3\end{bmatrix}$，$H=\begin{bmatrix}h_1&h_2&h_3\end{bmatrix}=\lambda'K\begin{bmatrix}r_1&r_2&t\end{bmatrix}$单应
			- 正交阵$||r_1||=||r_2||=1,r_1^Tr_2=0$得$$\begin{cases}h_1^TK^{-T}K^{-1}h_2=0\\h_1^TK^{-T}K^{-1}h_1=h_2^TK^{-T}K^{-1}h_2\end{cases}$$
			- 每幅图像提供2个内参数约束，共5个内参数，至少需要3张图像
			- 已知$H$，$K$，可得$r_1$，$r_2$，$t$，$r_3=r_1\times r_2$
		- 基于一维标志物的相机标定
			- 优势：可被多个相机无遮挡地观察到
	- 视觉三维重建概述
		- 图像->稀疏点云
		- 稀疏点云->稠密点云
		- 稠密点云->网格
		- 网格->模型
		- sfM：利用运动相机计算三维点云（结构估计、运动估计）
	- 两视角三维重建
		- 特征点提取：SIFT
		- 特征点匹配：SIFT描述子
		- 基础矩阵F估计：8点法等（$x_1^TEx_2=0$）
		- 本质矩阵$E=K_1^TFK_2$
		- 外参$\begin{bmatrix}R|t\end{bmatrix}$
			- 4个可能解，对应点是否在两个相机前方，计算$X-C=X+R^Tt$与$R(3,:)^T$夹角，选择位于两相机前方点数最多的解
		- 三角化
		- 点云
	- 多视角三维重建
		- 思路
			- 相邻视角进行两视角重建得到局部点云
			- 局部点云配准融合得到整体点云
		- 捆绑调整（光束平差法）
			- 输入各相机观测到的2D图像点，输出各相机位姿
			- 优化：最小化重投影误差（无量纲）$min\sum_i\sum_j(\tilde{x}_i^j-K\begin{bmatrix}R_i|t_t\end{bmatrix}X^j)^2$
		- 增量式sfM
			- 选取种子相机并计算其位姿
			- 不断添加新的相机并重复进行捆绑调整，直至没有新的相机可以添加
		- 全局式sfM
			- 分别计算邻接相机之间相对变换关系
			- 旋转平均：一次性计算全局姿态
			- 平移平均：一次性计算全局位置
			- 捆绑调整得到最终相机位姿和场景结构
		- 视觉定位概述
			- 相机定位：相机在世界坐标系下位姿
			- 目标定位：目标在相机坐标系下位姿
		- 相机定位
			- 离线
				- 已知环境
					- 基于图像检索的定位方法
					- 基于2D-3D匹配的定位方法
						- n点透视（PnP）
							- P3P余弦定理，二元二次方程组有多解性
						- 直接线性变换DLT
							- 每对3D-2D匹配点提供两个约束方程，$\begin{bmatrix}R|t\end{bmatrix}$共12个变量，需要6对点
							- 旋转矩阵需满足约束$R\in SO(3)$，$R=U\Sigma V^T$，$R=\begin{cases}UV^T&det(UV^T)>0\\Udiag(1,1,-1)V^T&det(UV^T)<0\end{cases}$
					- 基于学习的定位方法：计算稳定性好，精度相对低，泛化能力差
				- 未知环境：SLAM
					- 数据关联：空间点与图像点/空间点与空间点/图像点与图像点关联
					- 闭环检测：检测闭环，缓解累积误差
					- 重定位：系统运行失败自动恢复定位功能
			- 在线
				- 基于滤波器的方法
					- 卡尔曼滤波器、粒子滤波器等
				- 基于几何的方法
				- 混合方法
		- 目标定位：
			- 识别物体->求取位姿
			- 实例级/类别级
			- 基于单幅RGB图像实例级：有监督6D（6自由度）物体姿态估计算法
				- 基于模板匹配
				- 直接法：输入图像->输出位姿
				- 基于PnP算法
					- 基于关键点
					- 基于稠密对应
16. 目标跟踪与行为预测
	- 目标跟踪：单目标/多目标，单摄像机/多摄像机
		- 传统目标跟踪
			- 运动表达：点/区域/轮廓/模型
			- 模板匹配法
				- 前一帧目标/模板T位置$(x,y)$，当前帧搜索位置$(x',y')$，则$argmax_{dx,dy}conv(T(x,y),I(x+dx,y+dy))$
			- 基于卡尔曼滤波的跟踪方法
				- 基本假设
					- 后验概率分布$p(x_{k-1}|y_{1:k-1})$为高斯分布
					- 状态转移方程和观测方程都是线性的，$x_k=Ax_{k-1}+Bu_{k-1}+\omega_{k-1}$，$y_k=Hx_k+v_k$
					- 系统噪声和测量噪声符合高斯分布，协方差矩阵分别为Q和R
				- 最小化差异$e_k=x_k-\hat{x}_k$，即最小化$P=E(ee^T)$的迹
				- 思路：
					- 预测$\hat{x}_k'=A\hat{x}_{k-1}$
					- 测量$y_k$
					- 更新（校正）$\hat{x}_k=\hat{x}_k'+K(y_k-H\hat{x}_k')$，$K$为卡尔曼增益矩阵
				- 滤波流程
					- 时间更新
						- $\hat{x}_k^-=A\hat{x}_{k-1}+Bu_{k-1}$
						- $P_k^-=AP_{k-1}A^T+Q$
					- 状态更新
						- $K_k=P_k^-H^T(HP_k^-H^T+R)^{-1}$
						- $\hat{x}_k=\hat{x}_k'+K(y_k-H\hat{x}_k')$
						- $P_k=(I-K_kH)P_k^-$
				- 扩展：EKF、UKF将非线性函数局部线性化
			- 相关滤波与跟踪
				- 用相关核计算响应（得到响应图），跟踪响应最大位置
		- 基于深度网络的目标跟踪
			- DNN特征+相关滤波
			- 直接使用DNN，全卷积网络视觉跟踪，VGG
	- 运动表达与行为识别
		- 运动表达：刻画运动前景的行为模式
		- 人的运动：整体非刚体，局部刚体
		- 传统运动表达：
			- 运动轨迹
				- 识别特征点
				- 直接连接、多项式曲线拟合、主曲线拟合
				- 无时间信息，无运动细节
			- 时空图表达
				- 帧间差分得到前景二值化图像$D(x,y,t)$，设运动长度为$\tau$
				- 运动能量图$E_\tau=\cup_{i-0}^{\tau-1}D(x,y,t-i)$
				- 运动历史图$H_\tau(x,y,t)=\begin{cases}\tau&D(x,y,t)=1\\max(0,H_t(x,y,t-1)-1)&otherwise\end{cases}$
				- 缺少局部信息，难以区分速度变化
		- 传统运动识别
			- 基于模板匹配的方法
				- 时序模板：在图像上提取基于不变矩（Hu矩）的运动特征（具有平移、旋转、尺度不变性），并用马氏距离度量测试序列与模板之间的相似性
			- 动态时间规整
				- 测试序列$C=\{c_1,...c_m\}$与参考序列$Q=\{q_1,...q_n\}$时间尺度不一致
				- $W=w_1,...w_k$对齐，$max\{m,n\}\leq K\leq m+n-1$，$w_t=(c_i,q_j)_k$
				- $DTW(C,Q)=min_W\{\frac{1}{K}\sum_K||c_i-q_j||\}$
				- 约束：
					- 首尾对齐：$w_1=(c_1,q_1)$，$w_k=(c_m,q_n)$
					- 单调约束：$w_t=(c_a,q_b)$，$w_{t-1}=(c_{a'},q_{b'})$$\Rightarrow$$0\leq a-a'\leq1$，$0\leq b-b'\leq1$
				- 可用动态规划求解，也可用穷举法（度量距离，只能向右、右下、下走，求解最小路径）
			- 基于状态转移图模型的方法
				- 每个静态姿势作为一个状态，求解不同状态联合概率，最大值作为分类行为的标准
				- 隐马尔可夫模型
					- 马尔可夫过程：未来不依赖于过去$X(t+1)=f(X(t))$
					- 马尔科夫链（OMM）：时间和状态都离散的马尔可夫过程
					- 隐马尔可夫模型（HMM）：观测并非由状态决定，而是存在条件概率关系
					- 描述：$(X,O,A,B,\pi)$，其中参数$\lambda=(A,B,\pi)$
						- 状态集合：$X=\{q_1,...q_N\}$
						- 观测值集合：$O=\{v_1,..v_M\}$
						- 状态转移矩阵：$A=(a_{ij})$，$a_{ij}=p(X_{t+1}=q_j|X_t=q_i)$
						- 观测概率矩阵：$B=(b_{ik})$，$b_{ik}=p(O_t=v_k|X_t=q_i)$
						- 初始状态分布：$\pi=\{\pi_i\}$，$\pi_i=p(X_1=q_i)$
					- 三个基本问题
						- 估值问题
							- 给定$\lambda$，$O$，求特定观测序列概率$p(O|\lambda)=\sum_Sp(O|S,\lambda)p(S|\lambda)$，$p(O|S,\lambda)=\prod_{t=1}^Tp(O_t|q_t,\lambda)=b_{q_1}(O_1)...b_{q_T}(O_T)$
							- 穷举法：复杂度高
							- 前向算法
							- 后向算法
						- 解码问题：
							- 给定$\lambda$，$O$，求内部状态$S=q_1,...q_T$
							- $\delta_k(i)=max_{q_1,...q_t-1}p[q_1,...q_{t-1},q_t=i,O_1,...O_t|\lambda]$
							- 维特比算法
						- 模型训练问题
							- 给定训练集合$O$，训练参数$\lambda$，使$P(O)$最大
							- 鲍姆-韦尔奇算法
		- 基于深度学习的行为识别方法
			- 采用两分支的结构：时间分支和空间分支
			- 循环神经网络RNN：
				- 将循环结构展开为连续的非线性操作，可处理时序数据
				- 训练：通过时间的反向传播BPTT
				- 问题：
					- 梯度爆炸：梯度裁剪等
					- 梯度小时：LSTM
			- 长短时记忆模块
				- 细胞状态长时间传递信息
				- 遗忘门（删除信息）、输入门（添加信息）、输出门
				- 门通过sigmoid函数和逐元素乘法构建成
			- CNN（特征学习）+LSTM